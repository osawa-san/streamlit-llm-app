import streamlit as st
from openai import OpenAI
import os
from dotenv import load_dotenv

# Load environment variables for local development
load_dotenv()

# âœ… Secrets ã‹ã‚‰ã‚­ãƒ¼ã‚’å–å¾—
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Secretsã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.info("Streamlit Community Cloudã‚’ãŠä½¿ã„ã®å ´åˆ:")
    st.code("""
ã‚¢ãƒ—ãƒªã®è¨­å®š > Secrets ã§ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„:

OPENAI_API_KEY = "your-api-key-here"
    """)
    st.stop()
else:
    try:
        client = OpenAI(api_key=api_key)
        st.success("âœ… OpenAI APIã‚­ãƒ¼ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸï¼")
    except Exception as e:
        st.error(f"âŒ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
        st.stop()

st.title("ğŸ¤– Streamlit LLM App")
st.write("OpenAI APIã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("ä½•ã‹è³ªå•ã—ã¦ãã ã•ã„..."):
    # Display user message in chat message container
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Generate response
    with st.chat_message("assistant"):
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ]
            )
            assistant_response = response.choices[0].message.content
            st.markdown(assistant_response)
            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        except Exception as e:
            error_message = str(e)
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}")
            
            # å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã«å¿œã˜ãŸã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
            if "429" in error_message or "quota" in error_message.lower():
                st.warning("ğŸš¨ **APIåˆ©ç”¨åˆ¶é™ã‚¨ãƒ©ãƒ¼ (Error 429)**")
                st.info("""
**è§£æ±ºæ–¹æ³•:**
1. OpenAI Platform (https://platform.openai.com/usage) ã§ä½¿ç”¨é‡ã‚’ç¢ºèª
2. è«‹æ±‚è¨­å®š (https://platform.openai.com/account/billing) ã§ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’è¿½åŠ 
3. æœˆæ¬¡ãƒªã‚»ãƒƒãƒˆã¾ã§å¾…æ©Ÿï¼ˆç„¡æ–™æ ã®å ´åˆï¼‰
4. æ–°ã—ã„OpenAIã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§åˆ¥ã®APIã‚­ãƒ¼ã‚’å–å¾—
                """)
            elif "401" in error_message:
                st.info("ğŸ”‘ APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯æœŸé™åˆ‡ã‚Œã§ã™ã€‚æ–°ã—ã„ã‚­ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
            else:
                st.info("ğŸ”§ ä¸€æ™‚çš„ãªå•é¡Œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")